@ARTICLE{Cook1982-eq,
  title   = "Residuals and inï¬‚uence in regression",
  author  = "Cook, R Dennis and Weisberg, Sanford",
  journal = "Monographs on Statistics and Applied Probability",
  year    =  1982
}

@BOOK{Gelman2013-st,
  title     = "Bayesian Data Analysis, Third Edition",
  author    = "Gelman, A and Carlin, JB and Stern, HS and Dunson, DB and
               Vehtari, A and Rubin, DB",
  abstract  = "Now in its third edition, this classic book is widely considered
               the leading text on Bayesian methods, lauded for its accessible,
               practical approach to analyzing data and solving research
               problems. Bayesian Data Analysis , Third Edition continues to
               take an applied ...",
  publisher = "Taylor \& Francis",
  series    = "Chapman \& Hall/CRC Texts in Statistical Science",
  year      =  2013
}

@ARTICLE{OHagan2003-bc,
  title     = "{HSSS} Model Criticism",
  author    = "O'Hagan, A",
  abstract  = "There has been an enormous surge in practical applications of
               Bayesian statistics in the last decade. The primary reason for
               this has been the development of MCMC tools for computing
               posterior inferences. HSSS has played a major part in that
               process, through helping to ...",
  journal   = "Highly Structured Stochastic Systems",
  publisher = "Oxford University Press",
  pages     = "423--444",
  year      =  2003
}


@INPROCEEDINGS{Lloyd2014-nz,
  title         = "Automatic Construction and {Natural-Language} Description of
                   Nonparametric Regression Models",
  author        = {Lloyd, James Robert and Duvenaud, David and Grosse, Roger
                   and Tenenbaum, Joshua B. and Ghahramani, Zoubin},
  journal       = "Association for the Advancement of Artificial Intelligence
                   (AAAI)"
}


@INPROCEEDINGS{Grosse2012-zf,
  title      = "Exploiting compositionality to explore a large space of model
                structures",
  author     = "Grosse, Roger and Salakhutdinov, Ruslan R and Freeman, William
                T. and Tenenbaum, Joshua B.",
  abstract   = "The recent proliferation of richly structured probabilistic
                models raises the question of how to automatically determine an
                appropriate model for a dataset. We investigate this question
                for a space of matrix decomposition models which can express a
                variety of widely used models from unsupervised learning. To
                enable model selection, we organize these models into a
                context-free grammar which generates a wide variety of
                structures through the compositional application of a few
                simple rules. We use our grammar to generically and efficiently
                infer latent components and estimate predictive likelihood for
                nearly 2500 structures using a small toolbox of reusable
                algorithms. Using a greedy search over our grammar, we
                automatically choose the decomposition structure from raw data
                by evaluating only a small fraction of all models. The proposed
                method typically finds the correct structure for synthetic data
                and backs off gracefully to simpler models under heavy noise.
                It learns sensible structures for datasets as diverse as image
                patches, motion capture, 20 Questions, and U.S. Senate votes,
                all using exactly the same code.",
  year       =  2012,
  journal    = "Uncertainty in Artificial Intelligence"
}

@INPROCEEDINGS{Thornton2013-zg,
  title     = "{Auto-WEKA}: Combined Selection and Hyperparameter Optimization
               of Classification Algorithms",
  booktitle = "Proceedings of the 19th {ACM} {SIGKDD} International Conference
               on Knowledge Discovery and Data Mining",
  author    = "Thornton, Chris and Hutter, Frank and Hoos, Holger H. and
               Leyton-Brown, Kevin",
  abstract  = "Abstract Many different machine learning algorithms exist;
               taking into account each algorithm's hyperparameters, there is a
               staggeringly large number of possible alternatives overall. We
               consider the problem of simultaneously selecting a learning
               algorithm and ...",
  publisher = "ACM",
  pages     = "847--855",
  series    = "KDD '13",
  year      =  2013,
  address   = "New York, NY, USA",
  keywords  = "hyperparameter optimization, model selection, weka"
}

@misc{stan-software:2014,
  author = {{Stan Development Team}},
  year = {2014},
  title = {Stan: A C++ Library for Probability and Sampling,
           Version 2.2},
  url = {http://mc-stan.org/}
}

@INPROCEEDINGS{Goodman2012-pf,
  title         = "Church: a language for generative models",
  booktitle     = "Uncertainty in Artificial Intelligence ({UAI})",
  author        = "Goodman, Noah and Mansinghka, Vikash and Roy, Daniel and
                   Bonawitz, Keith and Tarlow, Daniel",
  abstract      = "We introduce Church, a universal language for describing
                   stochastic generative processes. Church is based on the Lisp
                   model of lambda calculus, containing a pure Lisp as its
                   deterministic subset. The semantics of Church is defined in
                   terms of evaluation histories and conditional distributions
                   on such histories. Church also includes a novel language
                   construct, the stochastic memoizer, which enables simple
                   description of many complex non-parametric models. We
                   illustrate language features through several examples,
                   including: a generalized Bayes net in which parameters
                   cluster over trials, infinite PCFGs, planning by inference,
                   and various non-parametric clustering models. Finally, we
                   show how to implement query on any Church program, exactly
                   and approximately, using Monte Carlo techniques.",
  journal       = "arXiv [cs.PL]",
  publisher     = "arxiv.org",
  month         =  06,
  year          =  2012,
  archivePrefix = "arXiv",
  primaryClass  = "cs.PL"
}

@INPROCEEDINGS{Meulders1998-xo,
  title     = "Generalizing the probability matrix decomposition model: an
               example of Bayesian model checking and model expansion",
  booktitle = "Assumptions, Robustness, and Estimation Methods in Multivariate
               Modeling",
  author    = "Meulders, Michel and Gelman, Andrew and Van Mechelen, Iven and
               De Boeck, Paul",
  abstract  = "CiteSeerX - Document Details (Isaac Councill, Lee Giles, Pradeep
               Teregowda): Probability matrix decomposition (PMD) models can be
               used to explain observed associations between two sets of
               elements. More specifically, observed associations are modeled
               as a deterministic function of B latent Bernoulli variables that
               are realized for each element. To estimate the parameters of
               this model, a sample of the posterior distribution is computed
               with a data augmentation algorithm. The obtained posterior
               sample can also be used to assess the fit of the model with the
               technique of posterior predictive checks. In this paper a PMD
               model is applied to data on psychiatric diagnosis. In checking
               the model for this analysis, we focus on the appropriateness of
               the prior distribution for a set of latent parameters. Based on
               the posterior distribution for the values of the parameters
               corresponding to the observed data, we conclude that a
               relatively flat prior distribution is inappropriate. In order to
               solve this problem, a mixture prior density with two beta
               distributed components ...",
  publisher = "Citeseer",
  year      =  1998
}

@ARTICLE{Gretton2008-ik,
  title    = "A kernel method for the two-sample-problem",
  author   = "Gretton, A and Borgwardt, KM and Rasch, M and Sch{\"{o}}lkopf, B
              and Smola, A",
  abstract = "Abstract We propose two statistical tests to determine if two
              samples are from different distributions. Our test statistic is
              in both cases the distance between the means of the two samples
              mapped into a reproducing kernel Hilbert space (RKHS). The first
              test is based ...",
  journal  = "Journal of Machine Learning Research",
  year     =  2008
}





