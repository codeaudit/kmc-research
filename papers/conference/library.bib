
@MISC{Stan_Development_Team2014-ha,
  title  = "Stan: A {C++} Library for Probability and Sampling, Version 2.2",
  author = "{Stan Development Team}",
  year   =  2014
}

@BOOK{Popper2005-qq,
  title     = "The logic of scientific discovery",
  author    = "Popper, K",
  abstract  = "Described by the philosopher AJ Ayer as a work of'great
               originality and power', this book revolutionized contemporary
               thinking on science and knowledge. Ideas such as the now
               legendary doctrine of'falsificationism'electrified the
               scientific community, influencing even ...",
  publisher = "Routledge",
  year      =  2005
}

@ARTICLE{Koller1997-am,
  title     = "Effective Bayesian inference for stochastic programs",
  author    = "Koller, D and McAllester, D and Pfeffer, A",
  abstract  = "Abstract In this paper, we propose a stochastic version of a
               general purpose functional programming language as a method of
               modeling stochastic processes. The language contains random
               choices, conditional statements, structured values, defined
               functions, ...",
  journal   = "Association for the Advancement of Artificial Intelligence
               (AAAI)",
  publisher = "aaai.org",
  year      =  1997
}

@ARTICLE{Gelman2003-xx,
  title     = "A {Bayesian} Formulation of Exploratory Data Analysis and
               goodness‐of‐fit Testing",
  author    = "Gelman, Andrew",
  abstract  = "R\'{e}sum\'{e} Analyse de donn\'{e}es exploratrices et
               inf\'{e}rence (EDA) Bay\'{e}sienne (ou, en large,
               mod\'{e}lisation de statistiques complexes)-qui sont
               g\'{e}n\'{e}ralement consid\'{e}r\'{e}es comme \'{e}tant des
               paradigmes statistiques non relies. Dans cet article, nous
               pr\'{e}sentons un cadre pour l' ...",
  journal   = "Int. Stat. Rev.",
  publisher = "Wiley Online Library",
  year      =  2003
}

@ARTICLE{Cowles1996-qy,
  title     = "Markov Chain Monte Carlo Convergence Diagnostics: A Comparative
               Review",
  author    = "Cowles, Mary Kathryn and Carlin, Bradley P",
  abstract  = "A critical issue for users of Markov chain Monte Carlo (MCMC)
               methods in applications is how to determine when it is safe to
               stop sampling and use the samples to estimate characteristics of
               the distribution of interest. Research into methods of computing
               theoretical convergence bounds holds promise for the future but
               to date has yielded relatively little of practical use in
               applied work. Consequently, most MCMC users address the
               convergence problem by applying diagnostic tools to the output
               produced by running their samplers. After giving a brief
               overview of the area, we provide an expository review of 13
               convergence diagnostics, describing the theoretical basis and
               practical implementation of each. We then compare their
               performance in two simple models and conclude that all of the
               methods can fail to detect the sorts of convergence failure that
               they were designed to identify. We thus recommend a combination
               of strategies aimed at evaluating and accelerating MCMC sampler
               convergence, including applying diagnostic procedures to a small
               number of parallel chains, monitoring autocorrelations and
               cross-correlations, and modifying parametrizations or sampling
               algorithms appropriately. We emphasize, however, that it is not
               possible to say with certainty that a finite sample from an MCMC
               algorithm is representative of an underlying stationary
               distribution.",
  journal   = "J. Am. Stat. Assoc.",
  publisher = "American Statistical Association",
  volume    =  91,
  number    =  434,
  pages     = "883--904",
  month     =  "1~" # jun,
  year      =  1996
}

@ARTICLE{Benjamini_undated-mh,
  title    = "Controlling the False Discovery Rate: A Practical and Powerful
              Approach to Multiple Testing",
  author   = "Benjamini, Yoav and Hochberg, Yosef",
  journal  = "J. R. Stat. Soc. Series B Stat. Methodol."
}

@MISC{noauthor_2014-kp,
  title    = "Deep learning tutorial - http://www.deeplearning.net/tutorial/",
  year     =  2014
}

@ARTICLE{Parzen1962-hk,
  title     = "On estimation of a probability density function and mode",
  author    = "Parzen, E",
  abstract  = "The problem of estimation of a probability density function f
               (x) is interesting, for many reasons. As one possible
               application, we mention the problem of estimating the hazard, or
               conditional rate of failure, function /(ж)/1-F (x), where F (x)
               is the distribution function ...",
  journal   = "Ann. Math. Stat.",
  publisher = "ssg.mit.edu",
  year      =  1962
}

@ARTICLE{Rosenblatt1956-hx,
  title     = "Remarks on Some Nonparametric Estimates of a Density Function",
  author    = "Rosenblatt, Murray",
  abstract  = "Project Euclid - mathematics and statistics online",
  journal   = "Ann. Math. Stat.",
  publisher = "Institute of Mathematical Statistics",
  volume    =  27,
  number    =  3,
  pages     = "832--837",
  month     =  sep,
  year      =  1956,
  issn_alt  = "2168-8990"
}

@ARTICLE{Guttman1967-my,
  title     = "The Use of the Concept of a Future Observation in
               {goodness-of-fit} Problems",
  author    = "Guttman, Irwin",
  abstract  = "An attack on the problem of goodness of fit is made by combining
               a Bayesian and sampling argument; the Bayesian part is effected
               by using the distribution of a future observation, while the
               sampling argument concerns itself with the distribution of a
               {"}chi-squared like{"} statistic, which measures discrepancies
               of observed frequencies from those predicted by the distribution
               of the future observation. Examples are given for the case of
               sampling from the binomial, Poisson and normal distributions. An
               interesting application arising from the above approach is a
               procedure for estimating the degree of a polynomial response
               function.",
  journal   = "J. R. Stat. Soc. Series B Stat. Methodol.",
  publisher = "Wiley for the Royal Statistical Society",
  volume    =  29,
  number    =  1,
  pages     = "83--100",
  year      =  1967
}

@ARTICLE{Bayarri2007-cp,
  title     = "Bayesian Checking of the Second Levels of Hierarchical Models",
  author    = "Bayarri, M J and Castellanos, M E",
  abstract  = "Project Euclid - mathematics and statistics online",
  journal   = "Stat. Sci.",
  publisher = "Institute of Mathematical Statistics",
  volume    =  22,
  number    =  3,
  pages     = "322--343",
  month     =  aug,
  year      =  2007,
  keywords  = "Model checking; model criticism; objective Bayesian methods;
               p-values; conflict; empirical-Bayes; posterior predictive;
               partial posterior predictive",
  issn_alt  = "2168-8745"
}

@ARTICLE{Marshall2007-hd,
  title     = "Identifying outliers in Bayesian hierarchical models: a
               simulation-based approach",
  author    = "Marshall, E C and Spiegelhalter, D J",
  abstract  = "Project Euclid - mathematics and statistics online",
  journal   = "Bayesian Anal.",
  publisher = "International Society for Bayesian Analysis",
  volume    =  2,
  number    =  2,
  pages     = "409--444",
  month     =  jun,
  year      =  2007,
  keywords  = "Hierarchical models; Diagnostics; Outliers; Distributional
               assumptions",
  issn_alt  = "1931-6690"
}

@TECHREPORT{Gelfand1992-ow,
  title       = "Model determination using predictive distributions with
                 implementation via sampling-based methods",
  author      = "Gelfand, A E and Dey, D K and Chang, H",
  abstract    = "Abstract: Model determination is divided into the issues of
                 model adequacy and model selection. Predictive distributions
                 are used to address both issues. This seems natural since,
                 typically, prediction is a primary purpose for the chosen
                 model . A cross-validation ...",
  publisher   = "DTIC Document",
  number      =  462,
  institution = "Stanford Uni CA Dept Stat",
  year        =  1992
}

@ARTICLE{Box1980-ud,
  title     = "Sampling and {Bayes'} Inference in Scientific Modelling and
               Robustness",
  author    = "Box, George E P",
  abstract  = "Scientific learning is an iterative process employing Criticism
               and Estimation. Correspondingly the formulated model factors
               into two complementary parts--a predictive part allowing model
               criticism, and a Bayes posterior part allowing estimation.
               Implications for significance tests, the theory of precise
               measurement and for ridge estimates are considered. Predictive
               checking functions for transformation, serial correlation, bad
               values, and their relation with Bayesian options are considered.
               Robustness is seen from a Bayesian viewpoint and examples are
               given. For the bad value problem a comparison with M estimators
               is made.",
  journal   = "J. R. Stat. Soc. Ser. A",
  publisher = "Wiley for the Royal Statistical Society",
  volume    =  143,
  number    =  4,
  pages     = "383--430",
  year      =  1980
}

@ARTICLE{Bayarri1999-ty,
  title    = "Quantifying surprise in the data and model verification",
  author   = "Bayarri, M J and Berger, J O",
  journal  = "Bayes. Stat.",
  year     =  1999
}

@INPROCEEDINGS{Iwata2013-yj,
  title         = "Warped Mixtures for Nonparametric Cluster Shapes",
  booktitle     = "Conf. on Unc. in Art. Int. ({UAI})",
  author        = "Iwata, Tomoharu and Duvenaud, David and Ghahramani, Zoubin",
  abstract      = "A mixture of Gaussians fit to a single curved or
                   heavy-tailed cluster will report that the data contains many
                   clusters. To produce more appropriate clusterings, we
                   introduce a model which warps a latent mixture of Gaussians
                   to produce nonparametric cluster shapes. The possibly
                   low-dimensional latent mixture model allows us to summarize
                   the properties of the high-dimensional clusters (or density
                   manifolds) describing the data. The number of manifolds, as
                   well as the shape and dimension of each manifold is
                   automatically inferred. We derive a simple inference scheme
                   for this model which analytically integrates out both the
                   mixture parameters and the warping function. We show that
                   our model is effective for density estimation, performs
                   better than infinite Gaussian mixture models at recovering
                   the true number of clusters, and produces interpretable
                   summaries of high-dimensional datasets.",
  journal       = "arXiv [stat.ML]",
  publisher     = "arxiv.org",
  year          =  2013,
  archivePrefix = "arXiv",
  primaryClass  = "stat.ML"
}

@ARTICLE{Peel2000-pv,
  title     = "Robust mixture modelling using the t distribution",
  author    = "Peel, D and McLachlan, G J",
  abstract  = "Normal mixture models are being increasingly used to model the
               distributions of a wide variety of random phenomena and to
               cluster sets of continuous multivariate data. However, for a set
               of data containing a group or groups of observations with longer
               than normal tails or atypical observations, the use of normal
               components may unduly affect the fit of the mixture model. In
               this paper, we consider a more robust approach by modelling the
               data by a mixture of t distributions. The use of the ECM
               algorithm to fit this t mixture model is described and examples
               of its use are given in the context of clustering multivariate
               data in the presence of atypical observations in the form of
               background noise.",
  journal   = "Stat. Comput.",
  publisher = "Kluwer Academic Publishers",
  volume    =  10,
  number    =  4,
  pages     = "339--348",
  month     =  "1~" # oct,
  year      =  2000,
  issn_alt  = "1573-1375"
}

@ARTICLE{Stigler1977-dd,
  title     = "Do Robust Estimators Work with Real Data?",
  author    = "Stigler, Stephen M",
  abstract  = "Project Euclid - mathematics and statistics online",
  journal   = "Ann. Stat.",
  publisher = "Institute of Mathematical Statistics",
  volume    =  5,
  number    =  6,
  pages     = "1055--1098",
  month     =  nov,
  year      =  1977,
  keywords  = "62-02; $M$-estimators; trimmed means; simulation; Monte Carlo;
               median; bias; adaptive estimators; skewness; kurtosis",
  issn_alt  = "2168-8966"
}

@BOOK{Rasmussen2006-ml,
  title     = "Gaussian Processes for Machine Learning",
  author    = "Rasmussen, C E and Williams, C K",
  publisher = "The MIT Press, Cambridge, MA, USA",
  year      =  2006
}

@ARTICLE{Bickel1969-ao,
  title     = "A Distribution Free Version of the Smirnov Two Sample Test in
               the p-Variate Case",
  author    = "Bickel, P J",
  abstract  = "1. Introduction. One of the classic problems of the theory of
               nonparametric inference is testing whether two samples come from
               the same or different populations. If the observations are
               univariate and we suppose only that the parent populations are
               governed by a ...",
  journal   = "Ann. Math. Stat.",
  publisher = "Institute of Mathematical Statistics",
  volume    =  40,
  number    =  1,
  pages     = "1--23",
  month     =  "1~" # feb,
  year      =  1969
}

@INPROCEEDINGS{Hotelling1951-jd,
  title     = "A Generalized t-test and Measure of Multivariate Dispersion",
  booktitle = "Proc. 2nd Berkeley Symp. Math. Stat. and Prob.",
  author    = "Hotelling, Harold",
  abstract  = "Project Euclid - mathematics and statistics online",
  journal   = "Proceedings of the second Berkeley symposium",
  publisher = "The Regents of the University of California",
  year      =  1951,
  keywords  = "Hotelling T-squared distribution"
}

@ARTICLE{Rubin1984-tw,
  title     = "Bayesianly Justifiable and Relevant Frequency Calculations for
               the Applied Statistician",
  author    = "Rubin, Donald B",
  journal   = "Ann. Stat.",
  publisher = "Institute of Mathematical Statistics",
  volume    =  12,
  number    =  4,
  pages     = "1151--1172",
  year      =  1984,
  keywords  = "62-07; Calibration; empirical Bayes; inference; model
               monitoring; operating characteristics; posterior predictive
               checks; stopping rules",
  issn_alt  = "2168-8966"
}

@INPROCEEDINGS{Goodman2008-ok,
  title     = "Church : a language for generative models",
  booktitle = "Conf. on Unc. in Art. Int. ({UAI})",
  author    = "Goodman, Noah D and Mansinghka, Vikash K and Roy, Daniel M and
               Bonawitz, Keith and Tenenbaum, Joshua B",
  journal   = "Proceedings of the Conference on Uncertainty in Artificial
               Intelligence (UAI)",
  year      =  2008
}

@ARTICLE{Geweke2004-yx,
  title    = "Getting It Right",
  author   = "Geweke, John",
  journal  = "J. Am. Stat. Assoc.",
  volume   =  99,
  number   =  467,
  pages    = "799--804",
  month    =  sep,
  year     =  2004
}

@ARTICLE{Gelman2013-am,
  title    = "Understanding posterior p-values",
  author   = "Gelman, Andrew",
  journal  = "Elec. J. Stat.",
  year     =  2013,
  keywords = "and phrases; bayesian inference; model checking; p-value;
              posterior; predictive check; u-value"
}

@ARTICLE{Hinton2007-eo,
  title    = "To Recognize Shapes, First Learn to Generate Images",
  author   = "Hinton, Geoffrey E",
  journal  = "Prog. Brain Res.",
  volume   =  165,
  pages    = "535--547",
  year     =  2007
}

@ARTICLE{Gelman1996-ez,
  title    = "Posterior predictive assessment of model fitness via realized
              discrepancies",
  author   = "Gelman, Andrew and Meng, Xiao-Li and Stern, Hal",
  journal  = "Stat. Sin.",
  volume   =  6,
  pages    = "733--807",
  year     =  1996,
  keywords = "and phrases; bayesian p -value; discrepancy; graphical assess-;
              ment; mixture model; model criticism; p -value; posterior
              predictive p -value; prior predictive; realized discrepancy; χ 2
              test"
}

@INPROCEEDINGS{Wilson2013-eq,
  title     = "Gaussian Process Covariance Kernels for Pattern Discovery and
               Extrapolation",
  booktitle = "Proc. Int. Conf. Machine Learn.",
  author    = "Wilson, Andrew Gordon and Adams, Ryan Prescott",
  journal   = "Proc. Int. Conf. Machine Learn.",
  year      =  2013
}

@INPROCEEDINGS{Grosse2012-zi,
  title     = "Exploiting compositionality to explore a large space of model
               structures",
  booktitle = "Conf. on Unc. in Art. Int. ({UAI})",
  author    = "Grosse, Roger B and Salakhutdinov, Ruslan and Freeman, William T
               and Tenenbaum, Joshua B",
  year      =  2012
}

@INPROCEEDINGS{Milch2005-qc,
  title     = "{BLOG}: Probabilistic models with unknown objects",
  booktitle = "Proc. Int. Joint Conf. on Artificial Intelligence",
  author    = "Milch, B and Marthi, B and Russel, S and Sontag, D and Ong, D L
               and Kolobov, A",
  journal   = "Proceedings of the International Joint Conference on Artificial
               Intelligence",
  year      =  2005
}

@ARTICLE{Robins2000-oz,
  title    = "Asymptotic Distribution of {p-values} in Composite Null Models",
  author   = "Robins, James M and van der Vaart, Aad and Venture, Valerie",
  journal  = "J. Am. Stat. Assoc.",
  volume   =  95,
  number   =  452,
  pages    = "1143--1156",
  year     =  2000,
  keywords = "asymptotic"
}

@ARTICLE{Vehtari2012-oh,
  title    = "A survey of {Bayesian} predictive methods for model assessment,
              selection and comparison",
  author   = "Vehtari, Aki and Ojanen, Janne",
  journal  = "Stat. Surv.",
  volume   =  6,
  pages    = "142--228",
  year     =  2012,
  keywords = "62-02, 62C10Bayesian, predictive, model assessment; and phrases;
              bayesian; cross-validation; decision theory; expected utility;
              information cri-; model; model assessment; predictive; selection"
}

@ARTICLE{Gretton2008-gs,
  title    = "A Kernel Method for the {two-sample} Problem",
  author   = "Gretton, Arthur and Borgwardt, Karsten M and Rasch, Malte J and
              Sch{\"{o}}lkopf, Berhard and Smola, Alexander",
  journal  = "Journal of Machine Learning Research",
  volume   =  1,
  pages    = "1--10",
  year     =  2008
}

@ARTICLE{Hinton2006-yw,
  title    = "A fast learning algorithm for deep belief nets",
  author   = "Hinton, Geoffrey E and Osindero, Simon and Teh, Yee Whye",
  journal  = "Neural Comput.",
  volume   =  18,
  number   =  7,
  pages    = "1527--1554",
  year     =  2006
}

@INPROCEEDINGS{Thornton2013-zg,
  title     = "{Auto-WEKA}: Combined Selection and Hyperparameter Optimization
               of Classification Algorithms",
  booktitle = "Proc. Int. Conf. on Knowledge Discovery and Data Mining",
  author    = "Thornton, Chris and Hutter, Frank and Hoos, Holger H and
               Leyton-Brown, Kevin",
  abstract  = "Abstract Many different machine learning algorithms exist;
               taking into account each algorithm's hyperparameters, there is a
               staggeringly large number of possible alternatives overall. We
               consider the problem of simultaneously selecting a learning
               algorithm and ...",
  journal   = "Proceedings of the 19th",
  publisher = "ACM",
  pages     = "847--855",
  series    = "KDD '13",
  year      =  2013,
  address   = "New York, NY, USA",
  keywords  = "hyperparameter optimization, model selection, weka"
}

@INPROCEEDINGS{Lloyd2014-nz,
  title         = "Automatic Construction and {Natural-Language} Description of
                   Nonparametric Regression Models",
  booktitle     = "Association for the Advancement of Artificial Intelligence
                   ({AAAI})",
  author        = "Lloyd, James Robert and Duvenaud, David and Grosse, Roger
                   and Tenenbaum, Joshua B and Ghahramani, Zoubin",
  abstract      = "This paper presents the beginnings of an automatic
                   statistician, focusing on regression problems. Our system
                   explores an open-ended space of possible statistical models
                   to discover a good explanation of the data, and then
                   produces a detailed report with figures and natural-language
                   text. Our approach treats unknown functions
                   nonparametrically using Gaussian processes, which has two
                   important consequences. First, Gaussian processes model
                   functions in terms of high-level properties (e.g.
                   smoothness, trends, periodicity, changepoints). Taken
                   together with the compositional structure of our language of
                   models, this allows us to automatically describe functions
                   through a decomposition into additive parts. Second, the use
                   of flexible nonparametric models and a rich language for
                   composing them in an open-ended manner also results in
                   state-of-the-art extrapolation performance evaluated over 13
                   real time series data sets from various domains.",
  journal       = "arXiv [stat.ML]",
  month         =  jul,
  year          =  2014,
  conference    = "Association for the Advancement of Artificial Intelligence
                   (AAAI)",
  archivePrefix = "arXiv",
  primaryClass  = "stat.ML"
}

@ARTICLE{OHagan2003-bc,
  title     = "{HSSS} Model Criticism",
  author    = "O'Hagan, A",
  abstract  = "There has been an enormous surge in practical applications of
               Bayesian statistics in the last decade. The primary reason for
               this has been the development of MCMC tools for computing
               posterior inferences. HSSS has played a major part in that
               process, through helping to ...",
  journal   = "Highly Structured Stochastic Systems",
  publisher = "Oxford University Press",
  pages     = "423--444",
  year      =  2003
}

@BOOK{Gelman2013-st,
  title     = "Bayesian Data Analysis, Third Edition",
  author    = "Gelman, A and Carlin, J B and Stern, H S and Dunson, D B and
               Vehtari, A and Rubin, D B",
  abstract  = "Now in its third edition, this classic book is widely considered
               the leading text on Bayesian methods, lauded for its accessible,
               practical approach to analyzing data and solving research
               problems. Bayesian Data Analysis , Third Edition continues to
               take an applied ...",
  publisher = "Taylor \& Francis",
  series    = "Chapman \& Hall/CRC Texts in Statistical Science",
  year      =  2013
}

@ARTICLE{Cook1982-eq,
  title    = "Residuals and inﬂuence in regression",
  author   = "Cook, Dennis and Weisberg, Sanford",
  journal  = "Mon. on Stat. and App. Prob.",
  year     =  1982
}

